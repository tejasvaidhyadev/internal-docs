---
title: 'Model Configuration'
description: 'Configure model architecture and initialization'
---

## Model Configuration

### ModelConfig

Configuration for model architecture and initialization.

<ParamField path="architecture" type="str" required>
  Model architecture specification. Supports major dense and MoE Hugging Face architectures including Qwen, LLaMA, Gemma.
  
  <Note>
    TSFM and other architectures coming soon.
  </Note>
</ParamField>

<ParamField path="init_method" type="str" default="normal">
  Weight initialization strategy:
  - `"none"`: Load from pre-trained model (Qwen/LLaMA/Gemma)
  - `"normal"`: Normal distribution initialization
  - `"xavier_uniform"`: Xavier uniform initialization
  - `"wang_init"`: Wang initialization method
</ParamField>

<ParamField path="model_path" type="str or None" default="None">
  Path to pre-trained model for continual training. Must be `None` if `init_method` is not `"none"`.
</ParamField>

<ParamField path="load_optimizer" type="bool or None" default="None">
  Whether to load optimizer state from checkpoint. Set to `True` for continual training from checkpoint.
</ParamField>

## Example Configurations

<CodeGroup>
```python Pre-trained Model
from pynolano import ModelConfig

config = ModelConfig(
    architecture="Qwen/Qwen3-4B",
    init_method="none",
    model_path="./pretrained_model",
    load_optimizer=False
)
```

```python From Scratch
from pynolano import ModelConfig

config = ModelConfig(
    architecture="Qwen/Qwen3-4B",
    init_method="normal"
)
```

```python Continual Training
from pynolano import ModelConfig

config = ModelConfig(
    architecture="Qwen/Qwen3-4B",
    init_method="none",
    model_path="./checkpoint/global_step_1000",
    load_optimizer=True
)
```
</CodeGroup>

## Supported Architectures

<Tabs>
  <Tab title="Dense Models">
    - **LLaMA Series** 
    - **Qwen Series**
    - **Gemma Series**  
  </Tab>
  
  <Tab title="Mixture of Experts (MoE)">
    - **Qwen MoE**  
    - **DeepSeek**
    - **Mixtral** 
  </Tab>
  
  <Tab title="Time Series">
    - **TSFM**: Time Series Foundation Models
    - **Chronos**: Amazon Chronos models
    - **TimesFM**: Google TimesFM
  </Tab>
</Tabs>

you can request custom architecture if needed

<Warning>
  When using `init_method="none"`, you must provide a valid `model_path`. The model path should point to a compatible pre-trained model or checkpoint.
</Warning>
