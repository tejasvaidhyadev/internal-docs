---
title: Introduction
description: 'Automated Platform for Building Large Foundation Models'
---

<Frame>
  <img
    className="block dark:hidden"
    src="/logos/cube_exploded_hero.png"
    alt="Nolano.AI Logo"
  />
  <img
    className="hidden dark:block"
    src="/logos/cube_exploded_hero.png"
    alt="Nolano.AI Logo"
  />
</Frame>

# Nolano AI: An Automated Platform for Developing Large-Scale Foundation Models

<Note>
  **For AI/ML Researchers** at the frontier of foundation modeling research.
</Note>

The library seeks to abstract away the complexity of HPC, distributed training, tooling, systems and non-AI related engineering overhead involved in getting the foundation model research going.  
We allow AI researchers to focus on what matters most: **breakthrough innovations in foundation models**, by getting their experiment going in minutes, not months.

## What We Abstract Away

Our platform eliminates the boilerplate parts of foundation model research so you can focus on pushing the frontier:

<AccordionGroup>
  <Accordion title="Engineering Setup" icon="wrench">
    Months of engineering setup for distributed training across clusters - we handle the infrastructure complexity so you can focus on model innovation.
  </Accordion>
  
  <Accordion title="HPC Expertise" icon="microchip">
    Deep expertise in HPC, CUDA, parallelization strategies, and hardware optimization - no need to become a systems expert to train foundation models.
  </Accordion>
  
  <Accordion title="Data Pipelines" icon="database">
    Redundant implementation of data loaders, training loops, and evaluation pipelines - our battle-tested pipelines handle petabyte-scale datasets efficiently.
  </Accordion>
  
  <Accordion title="Configuration Management" icon="gear">
    Complex configuration management across different experiments and modalities - simplified configuration with intelligent defaults and validation.
  </Accordion>
</AccordionGroup>

## Supported Modalities

<CardGroup cols={2}>
  <Card
    title="Language & Code"
    icon="code"
    color="#935095"
    href="/tutorials/text-models"
  >
    Build state-of-the-art language and code models with support for all major architectures.
    
    See tutorial
  </Card>
  <Card
    title="Time Series"
    icon="chart-line"
    color="#B47BB6"
    href="/tutorials/time-series"
  >
    Create powerful forecasting models for both univariate and multivariate time series data.
    
    See tutorial
  </Card>
</CardGroup>

### Key Features

<AccordionGroup>
  <Accordion title="Tokenization Support">
    - Custom tokenizers for text & time series
    - BPE, WordPiece, SentencePiece implementations
  </Accordion>

  <Accordion title="Architecture Support">
    - Supports major dense (Encoder/Decoder) and Mixture-of-Experts architectures
    - Qwen, DeepSeek, Chronos, and TimeMoE
  </Accordion>

  <Accordion title="Distributed Training">
    - Multi-node, multi-GPU training out of the box
    - Data, model, and pipeline parallelism
    - Gradient accumulation and mixed precision training
    - Automatic sharding and load balancing
  </Accordion>

  <Accordion title="Data Pipeline">
    - High-performance data loading and preprocessing
    - Memory-efficient streaming for large datasets
    - Automatic data shuffling and batching
  </Accordion>

  <Accordion title="Training Optimization">
    - Adaptive learning rate scheduling
    - Gradient clipping and stability monitoring
    - Memory optimization techniques
    - Dynamic loss scaling for mixed precision
  </Accordion>

  <Accordion title="Evaluation & Monitoring">
    - Custom evaluation metrics support
    - Real-time training metrics and visualization
    - Supports Weights & Biases integration
  </Accordion>

  <Accordion title="Model Management">
    - Automatic checkpointing and versioning
    - Integration with Huggingface
  </Accordion>

  <Accordion title="Scalability & Performance">
    - Dynamic scaling based on workload
    - Optimized for cloud and on-premise deployments
  </Accordion>
</AccordionGroup>

## What You Get

<CardGroup cols={2}>
  <Card
    title="Zero-to-training in under an hour"
    icon="rocket"
    color="#935095"
  >
    Start your first experiment immediately with our streamlined workflow
  </Card>
  <Card
    title="One-command operations"
    icon="terminal"
    color="#B47BB6"
  >
    Data preparation, training, evaluation and inference with simple CLI commands
  </Card>
  <Card
    title="Built-in best practices"
    icon="star"
    color="#6F3A71"
  >
    Scalable distributed training, hyperparameter transfer and automated optimization
  </Card>
  <Card
    title="Production-ready"
    icon="check"
    color="#935095"
  >
    Models ready for deployment without additional engineering overhead
  </Card>
</CardGroup>

<Note>
  Ready to get started? Check out our [Quickstart Guide](/quickstart) to begin building your first foundation model.
</Note>

---

*Nolano AI: Democratizing Foundation Model Research*
