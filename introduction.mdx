---
title: Introduction
description: 'Automated Platform for Building Large Foundation Models'
---

<Frame>
  <img
    className="block dark:hidden"
    src="/logos/cube_exploded_hero.png"
    alt="Nolano.AI Logo"
  />
  <img
    className="hidden dark:block"
    src="/logos/cube_exploded_hero.png"
    alt="Nolano.AI Logo"
  />
</Frame>

# Nolano AI — Automated Platform for Building Large Foundation Models

<Note>
  **For AI/ML Researchers** at the frontier of foundation modeling research.
</Note>

The library seeks to abstract away the complexity of HPC, distributed training, tooling, systems and non-AI related engineering overhead involved in getting the foundation model research going.  
We allow AI researchers to focus on what matters most: **breakthrough innovations in foundation models**, by getting their experiment going in minutes, not months.

## What We Abstract Away

Our platform eliminates the boilerplate parts of foundation model research so you can focus on pushing the frontier:

<CardGroup cols={2}>
  <Card
    title="Engineering Setup"
    icon="wrench"
    color="#935095"
  >
    Months of engineering setup for distributed training across clusters
  </Card>
  <Card
    title="HPC Expertise" 
    icon="microchip"
    color="#B47BB6"
  >
    Deep expertise in HPC, CUDA, parallelization strategies, and hardware optimization
  </Card>
  <Card
    title="Data Pipelines"
    icon="database"
    color="#6F3A71"
  >
    Redundant implementation of data loaders, training loops, and evaluation pipelines
  </Card>
  <Card
    title="Configuration Management"
    icon="gear"
    color="#935095"
  >
    Complex configuration management across different experiments and modalities
  </Card>
</CardGroup>

## Supported Modalities

<Tabs>
  <Tab title="Language & Code">
    Build state-of-the-art language and code models with support for all major architectures.
  </Tab>
  <Tab title="Time Series">
    Create powerful forecasting models for both univariate and multivariate time series data.
  </Tab>
</Tabs>

### Key Features

<AccordionGroup>
  <Accordion title="Tokenization Support">
    - Supports all Hugging Face tokenizers
    - Custom tokenizers for text & time series
    - Flexible tokenization strategies
  </Accordion>

  <Accordion title="Architecture Support">
    - Major dense and MoE architectures
    - LLaMA, Qwen, DeepSeek
    - Custom architecture definitions
  </Accordion>
</AccordionGroup>

## What You Get

<CardGroup cols={2}>
  <Card
    title="Zero-to-training in under an hour"
    icon="rocket"
    color="#935095"
    href="/quickstart"
  >
    Start your first experiment immediately with our streamlined workflow
  </Card>
  <Card
    title="One-command operations"
    icon="terminal"
    color="#B47BB6"
    href="/quickstart"
  >
    Data preparation, training, evaluation and inference with simple CLI commands
  </Card>
  <Card
    title="Built-in best practices"
    icon="star"
    color="#6F3A71"
    href="/training"
  >
    Scalable distributed training, hyperparameter transfer and automated optimization
  </Card>
  <Card
    title="Production-ready"
    icon="check"
    color="#935095"
    href="/evaluation"
  >
    Models ready for deployment without additional engineering overhead
  </Card>
</CardGroup>

<Note>
  Ready to get started? Check out our [Quickstart Guide](/quickstart) to begin building your first foundation model.
</Note>

---

*Nolano.AI — Democratizing Foundation Model Research*
