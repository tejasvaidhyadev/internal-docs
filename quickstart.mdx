---
title: 'Quickstart'
description: 'Start building foundation models in minutes'
---

## Quick Start Guide

Get your first foundation model training in under an hour with these simple steps.

<Note>
  **Two Ways to Work with Nolano.AI**: This guide shows both the **Python SDK** (`pynolano`) for creating configuration files and the **CLI** (`nolano`) for executing operations. Both work together seamlessly - you write configs with the SDK and run them with the CLI.
</Note>

<Steps>
  <Step title="Prepare Your Data">
    Nolano.AI handles all data preprocessing with a single command. Here's a minimal config example for text data:

    ```python data_config.py
    from pynolano import DataPreparationConfig

    def build() -> DataPreparationConfig:
        return DataPreparationConfig(
            input_path = "./raw_data", # Can also be a readable  stream
            output_path = "./prepared_data",
            tokenization = "Qwen/Qwen3-4B",
        )
    ```

    Run data preparation:

    ```bash
    nolano prepare_data data_config.py
    ```
  </Step>

  <Step title="Train Your Model">
    Create a simple training configuration:

    ```python train_config.py
    from pynolano import DataConfig, OptimizationConfig, ExperimentConfig, ModelConfig

    def build() -> ExperimentConfig:
        return ExperimentConfig(
            data_configs=DataConfig(data_paths="./prepared_data"),
            model_config=ModelConfig("Qwen/Qwen3-4B"),
            optimization_config=OptimizationConfig(
                global_batch_size=32, 
                max_learning_rate=3e-4, 
                total_training_steps=1000
            )
        )
    ```

    Start training:
    
    ```bash
    nolano train train_config.py
    ```
  </Step>

  <Step title="Automatic Features">
    That's it! Your model is now training with automatic:

    <CardGroup cols={2}>
      <Card title="Distributed Training" icon="server" color="#935095">
        Data parallelism across available GPUs
      </Card>
      <Card title="Mixed Precision" icon="gauge" color="#B47BB6">
        Optimal performance with mixed precision training
      </Card>
      <Card title="Checkpointing" icon="floppy-disk" color="#6F3A71">
        Checkpoint saving every epoch
      </Card>
      <Card title="Metrics Logging" icon="chart-line" color="#935095">
        Real-time metrics logging
      </Card>
    </CardGroup>
  </Step>

  <Step title="Next Steps">
    After model training you can:

    <CodeGroup>
      ```bash Export to Hugging Face
      nolano convert_to_hf ./checkpoints/global_step_1000 config.yaml ./hf_model
      ```

      ```bash Run Evaluation
      nolano evaluate eval_config.py
      ```

      ```bash Run Inference
      nolano infer model_path input_data
      ```
    </CodeGroup>
  </Step>
</Steps>

## What's Next?

<CardGroup cols={3}>
  <Card
    title="Data Preparation"
    icon="database"
    href="/data-preparation"
    color="#935095"
  >
    Learn about advanced data preprocessing techniques and tokenization strategies
  </Card>
  <Card
    title="Model Configuration"
    icon="brain"
    href="/model-configuration"
    color="#B47BB6"
  >
    Explore different model architectures and initialization settings
  </Card>
  <Card
    title="Evaluation"
    icon="chart-bar"
    href="/evaluation"
    color="#6F3A71"
  >
    Understand how to evaluate your trained models and run inference
  </Card>
</CardGroup>

<Tip>
  Need help?  reach out to [support](mailto:hello@nolano.ai).
</Tip>
